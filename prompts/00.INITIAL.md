# AI-Native Infrastructure Harness

Build a harness that enables AI-driven development and operation of infrastructure services. The first service built with this harness will be a rate limiter—but the harness itself is the product.

## What We're Building

Two things:

1. **The Harness** — a framework for AI-native development and operations
2. **A Rate Limiter** — the first service built and operated entirely through the harness

The harness proves that infrastructure can be built and operated by AI with humans providing direction, not implementation.

---

## Core Principles

### Hermetic

Everything inside an observable boundary. Nothing outside.

- All state queryable via API
- All actions through APIs  
- All effects captured in events/metrics
- No SSH, no consoles, no hidden config
- If the AI can't see it, it doesn't exist

### Ticket-Driven

Work flows through structured intake.

- Human-generated tickets define objectives
- AI-generated tickets surface observed problems
- All work has explicit success criteria
- Progress tracked, outcomes recorded

### Invariant-Based

AI defines and maintains observable success criteria.

- Standing conditions that must always hold
- Observable through metrics/events layer
- Violations trigger automatic action
- Invariants evolve over time (proposed, tightened, retired)

---

## Harness Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                        THE HARNESS                          │
│                                                             │
│  ┌─────────────────────────────────────────────────────┐   │
│  │                   Ticket System                      │   │
│  │  - Structured intake (objectives, criteria, bounds)  │   │
│  │  - Human and AI can create tickets                   │   │
│  │  - Priority, status, assignment                      │   │
│  │  - Links to code changes, deployments, outcomes      │   │
│  └─────────────────────────────────────────────────────┘   │
│                            │                                │
│                            ▼                                │
│  ┌─────────────────────────────────────────────────────┐   │
│  │                   Agent Loop                         │   │
│  │  - Picks tickets from queue                          │   │
│  │  - Plans approach (queryable)                        │   │
│  │  - Executes via Action Executor                      │   │
│  │  - Verifies against success criteria                 │   │
│  │  - Closes or escalates                               │   │
│  └─────────────────────────────────────────────────────┘   │
│                            │                                │
│                            ▼                                │
│  ┌─────────────────────────────────────────────────────┐   │
│  │                 Action Executor                      │   │
│  │  - Code changes (git commits, PRs)                   │   │
│  │  - Deployments                                       │   │
│  │  - Config updates                                    │   │
│  │  - All actions bounded and auditable                 │   │
│  └─────────────────────────────────────────────────────┘   │
│                            │                                │
│                            ▼                                │
│  ┌─────────────────────────────────────────────────────┐   │
│  │             Invariant Evaluator                      │   │
│  │  - Queries Prometheus via API                        │   │
│  │  - Evaluates PromQL-defined invariants               │   │
│  │  - Creates tickets on violation                      │   │
│  │  - Detects anomalies → generates investigation       │   │
│  └─────────────────────────────────────────────────────┘   │
│                            │                                │
│                            ▼                                │
│  ┌─────────────────────────────────────────────────────┐   │
│  │                Knowledge Layer                       │   │
│  │  - AGENTS.md + standard repo structure               │   │
│  │  - Schema registry (API contracts)                   │   │
│  │  - Decision log (tickets, ADRs, outcomes)            │   │
│  │  - Runbook library (machine-readable)                │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
└─────────────────────────────────────────────────────────────┘
         │                                      ▲
         │ queries                              │ emits metrics/logs
         ▼                                      │
┌─────────────────────────────────────────────────────────────┐
│              OBSERVABILITY (Grafana Cloud)                  │
│                                                             │
│   Prometheus               Loki                             │
│   - Metrics storage        - Structured logs/events         │
│   - PromQL queries         - LogQL queries                  │
│                                                             │
└─────────────────────────────────────────────────────────────┘
                            ▲
                            │ emits
                ┌─────────────────────┐
                │   Rate Limiter      │
                │   (first subject)   │
                └─────────────────────┘
```

---

## Program Structure

The harness runs as multiple processes that communicate via the database and external services.

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                              PROCESSES                                       │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────────────────┐ │
│  │   harness.web   │  │  harness.agent  │  │  subjects.ratelimiter.serve │ │
│  │                 │  │                 │  │                             │ │
│  │  - Dashboard    │  │  - Agent loop   │  │  - The actual service       │ │
│  │  - Ticket API   │  │  - Claude calls │  │  - Emits metrics to Prom    │ │
│  │  - Invariant API│  │  - Tool exec    │  │  - Emits logs to Loki       │ │
│  │  - Action log   │  │  - Git commits  │  │  - Restarts on deploy       │ │
│  │                 │  │                 │  │                             │ │
│  │  Port 8000      │  │  (no port)      │  │  Port 8001                  │ │
│  └────────┬────────┘  └────────┬────────┘  └──────────────┬──────────────┘ │
│           │                    │                          │                 │
│           └──────────┬─────────┴──────────────────────────┘                 │
│                      │                                                      │
│                      ▼                                                      │
│           ┌─────────────────────┐                                           │
│           │      SQLite DB      │                                           │
│           │                     │                                           │
│           │  - tickets          │                                           │
│           │  - invariants       │                                           │
│           │  - actions_log      │                                           │
│           │  - config           │                                           │
│           └─────────────────────┘                                           │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
                      │
                      │ queries / emits
                      ▼
          ┌─────────────────────────┐
          │    Grafana Cloud        │
          │  (Prometheus + Loki)    │
          └─────────────────────────┘
```

### Process Responsibilities

**`harness.web`** (FastAPI server)
- Serves the dashboard UI
- Exposes REST API for tickets, invariants, actions
- Humans interact here (view state, approve tickets, create tickets)
- No Claude integration—just CRUD and display

**`harness.agent`** (Background worker)
- Runs the agent loop continuously
- Calls Claude API with tools
- Executes tool calls (file edits, deploys, queries)
- Creates git commits for code changes
- Updates ticket status in database

**`subjects.ratelimiter.serve`** (The service under management)
- The actual rate limiter service
- Knows nothing about the harness
- Emits Prometheus metrics via `/metrics` endpoint
- Emits structured logs to Loki
- Gets restarted by deploy script when new version ships

### Entry Points

```python
# harness/src/main.py

"""
Harness entry points.

Usage:
    python -m harness.web      # Start the web server
    python -m harness.agent    # Start the agent loop
    python -m harness.init     # Initialize database
"""

# harness.web
def run_web():
    """Start the FastAPI web server."""
    import uvicorn
    from .web.app import app
    uvicorn.run(app, host="0.0.0.0", port=8000)

# harness.agent  
def run_agent():
    """Start the agent loop."""
    from .agent_loop.loop import AgentLoop
    from .agent_loop.display import Display
    
    display = Display()
    loop = AgentLoop(display=display)
    loop.run_forever()

# harness.init
def run_init():
    """Initialize the database and default config."""
    from .db import init_db
    from .config import load_defaults
    
    init_db()
    load_defaults()
    print("Harness initialized.")
```

### Directory Structure (Expanded)

```
harness/
├── pyproject.toml              # Package config, dependencies
├── .env.example                # Environment template
│
├── src/
│   ├── __init__.py
│   ├── main.py                 # Entry points (web, agent, init)
│   ├── db.py                   # SQLAlchemy setup, session management
│   ├── config.py               # Load config from env/db
│   │
│   ├── models/                 # SQLAlchemy models
│   │   ├── __init__.py
│   │   ├── ticket.py
│   │   ├── invariant.py
│   │   └── action.py
│   │
│   ├── web/                    # FastAPI web server
│   │   ├── __init__.py
│   │   ├── app.py              # FastAPI app, mount routers
│   │   ├── routers/
│   │   │   ├── tickets.py      # /api/tickets
│   │   │   ├── invariants.py   # /api/invariants
│   │   │   └── actions.py      # /api/actions
│   │   └── templates/
│   │       ├── base.html
│   │       ├── dashboard.html
│   │       └── ticket_detail.html
│   │
│   ├── agent_loop/             # The Claude-powered agent
│   │   ├── __init__.py
│   │   ├── loop.py             # Main loop: check tickets, run Claude
│   │   ├── claude.py           # Claude API wrapper
│   │   ├── tools.py            # Tool definitions
│   │   ├── handlers/           # Tool implementations
│   │   │   ├── observability.py  # query_prometheus, query_loki
│   │   │   ├── knowledge.py      # read_file, search_code
│   │   │   ├── actions.py        # edit_file, deploy, run_tests
│   │   │   └── tickets.py        # create_ticket, add_note
│   │   └── display.py          # Rich terminal output
│   │
│   ├── observability/          # Grafana Cloud clients
│   │   ├── __init__.py
│   │   ├── prometheus.py       # PromQL query client
│   │   └── loki.py             # LogQL query client
│   │
│   └── invariants/             # Invariant evaluation
│       ├── __init__.py
│       └── evaluator.py        # Check invariants, create tickets
│
├── subjects/                   # Services managed by the harness
│   └── ratelimiter/
│       ├── pyproject.toml
│       ├── src/
│       │   ├── __init__.py
│       │   ├── main.py         # Entry point
│       │   ├── app.py          # FastAPI app
│       │   ├── bucket.py       # Token bucket logic
│       │   └── metrics.py      # Prometheus metrics setup
│       └── tests/
│           └── test_bucket.py
│
├── scripts/
│   ├── deploy.sh               # Deploy a subject service
│   └── simulate_traffic.py     # Generate test traffic
│
└── data/
    └── harness.db              # SQLite database
```

### How It Runs

**Development (3 terminals):**

```bash
# Terminal 1: Web server
python -m harness.web

# Terminal 2: Agent loop
python -m harness.agent

# Terminal 3: Rate limiter service
python -m subjects.ratelimiter.serve
```

**Production-ish (systemd or Docker Compose):**

```yaml
# docker-compose.yml
version: '3.8'

services:
  harness-web:
    build: .
    command: python -m harness.web
    ports:
      - "8000:8000"
    volumes:
      - ./data:/app/data
      - ./subjects:/app/subjects
    environment:
      - DATABASE_URL=sqlite:///data/harness.db
      - GRAFANA_API_KEY=${GRAFANA_API_KEY}
  
  harness-agent:
    build: .
    command: python -m harness.agent
    volumes:
      - ./data:/app/data
      - ./subjects:/app/subjects
    environment:
      - DATABASE_URL=sqlite:///data/harness.db
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - GRAFANA_API_KEY=${GRAFANA_API_KEY}
  
  ratelimiter:
    build: ./subjects/ratelimiter
    command: python -m ratelimiter.serve
    ports:
      - "8001:8001"
    environment:
      - GRAFANA_API_KEY=${GRAFANA_API_KEY}
```

### Data Flow

```
1. Human creates ticket via dashboard (or agent creates from invariant violation)
        │
        ▼
2. Ticket written to SQLite (status: pending)
        │
        ▼
3. Agent loop polls for pending tickets
        │
        ▼
4. Agent picks ticket, calls Claude with context + tools
        │
        ▼
5. Claude returns tool calls (e.g., query_prometheus, edit_file)
        │
        ▼
6. Agent executes tools:
   - Queries go to Grafana Cloud
   - File edits create git commits
   - Deploys run scripts that restart the service
        │
        ▼
7. Agent feeds results back to Claude
        │
        ▼
8. Loop continues until Claude says "done" or gives up
        │
        ▼
9. Agent updates ticket (status: completed/failed, outcome)
        │
        ▼
10. Dashboard shows updated state
```

---

## Component Specifications

### Observability Stack (External Services)

Use standard observability tooling rather than custom stores. This keeps the harness focused on orchestration, not reinventing monitoring.

**Recommended Stack:**

- **Metrics:** Prometheus + Grafana Cloud (or self-hosted)
- **Logs/Events:** Loki (pairs with Grafana) or Elasticsearch
- **Tracing:** Optional, Jaeger if needed

**Simpler Alternative (for PoC):**

- **Metrics + Logs:** Grafana Cloud Free Tier (includes Prometheus, Loki, Grafana)
  - 10K metrics series, 50GB logs/month — plenty for a PoC
  - No infrastructure to manage
  - Agent queries via HTTP API

**Setup:**

```bash
# Install Grafana Alloy (lightweight collector)
# Replaces Prometheus node exporter + promtail

# Or just push directly from Python:
pip install prometheus-client  # For metrics
pip install python-logging-loki  # For structured logs
```

**How the Agent Queries:**

```python
# Prometheus query (via Grafana Cloud API)
import requests

response = requests.get(
    "https://prometheus-prod-01-prod-us-east-0.grafana.net/api/prom/api/v1/query",
    params={"query": "rate(ratelimiter_requests_total[5m])"},
    headers={"Authorization": f"Bearer {GRAFANA_API_KEY}"}
)
result = response.json()

# Loki query (for structured events)
response = requests.get(
    "https://logs-prod-us-central1.grafana.net/loki/api/v1/query_range",
    params={
        "query": '{service="ratelimiter"} |= "request.rejected"',
        "start": start_timestamp,
        "end": end_timestamp
    },
    headers={"Authorization": f"Bearer {GRAFANA_API_KEY}"}
)
```

**What Services Emit:**

```python
# Metrics (Prometheus format)
from prometheus_client import Counter, Histogram, Gauge

requests_total = Counter(
    'ratelimiter_requests_total',
    'Total requests processed',
    ['client_id', 'allowed']
)

latency_histogram = Histogram(
    'ratelimiter_latency_seconds',
    'Request latency',
    ['endpoint']
)

# Structured logs (to Loki)
import logging
import logging_loki

handler = logging_loki.LokiHandler(
    url="https://logs-prod-us-central1.grafana.net/loki/api/v1/push",
    tags={"service": "ratelimiter"},
    auth=("user", GRAFANA_API_KEY)
)
logger = logging.getLogger("ratelimiter")
logger.addHandler(handler)

# Emit structured event
logger.info("request.processed", extra={
    "client_id": "client-47",
    "tokens_requested": 10,
    "allowed": True,
    "remaining": 90,
    "latency_ms": 4.2
})
```

---

### 1. Ticket System

A simple database-backed ticket queue. This is custom because it's core to the harness.

**Ticket Schema:**

```yaml
ticket:
  id: string                    # e.g., "TKT-001"
  type: enum                    # feature, improvement, incident, investigation
  status: enum                  # pending, in_progress, blocked, completed, failed
  created_by: enum              # human, agent
  created_at: timestamp
  updated_at: timestamp
  
  objective:
    description: string
    success_criteria:
      - metric: string          # Prometheus metric name
        condition: string       # PromQL condition, e.g., "< 500"
        current_value: optional
  
  constraints:
    - string
  
  context:
    related_components: [string]
    related_tickets: [string]
    related_docs: [string]
  
  execution:
    plan: optional string       # Agent's plan before execution
    actions_taken: [action_ref]
    outcome: optional string
    
  approval:
    required: boolean
    approved_by: optional string
    approved_at: optional timestamp
```

**API:**

```
POST   /tickets              # Create ticket
GET    /tickets              # List tickets (filterable)
GET    /tickets/{id}         # Get ticket details
PATCH  /tickets/{id}         # Update ticket (status, execution, etc.)
POST   /tickets/{id}/approve # Approve ticket (if approval required)
```

### 2. Invariant Evaluator

Continuous evaluation of standing conditions using Prometheus queries.

**Invariant Schema:**

```yaml
invariant:
  id: string
  name: string
  description: string
  status: enum                # active, proposed, retired
  
  condition:
    promql: string            # Full PromQL query
    operator: enum            # lt, gt, eq, lte, gte
    threshold: number
    
  evaluation:
    frequency: duration       # e.g., "1m"
    
  on_violation:
    action: enum              # alert, investigate, auto_remediate, escalate
    create_ticket: boolean
    ticket_type: optional enum
    auto_approve: boolean     # Can agent act without human approval?
    
  history:
    last_evaluated: timestamp
    last_violation: optional timestamp
    violation_count_24h: number
```

**Example Invariants:**

```yaml
invariants:
  - id: "inv-001"
    name: "latency_slo"
    description: "P99 latency must stay under 10ms"
    promql: "histogram_quantile(0.99, rate(ratelimiter_latency_seconds_bucket[5m]))"
    operator: "lt"
    threshold: 0.01           # 10ms in seconds
    on_violation:
      action: "investigate"
      create_ticket: true

  - id: "inv-002"
    name: "error_rate"
    description: "Error rate must stay under 0.1%"
    promql: |
      sum(rate(ratelimiter_requests_total{allowed="false"}[5m])) 
      / sum(rate(ratelimiter_requests_total[5m]))
    operator: "lt"
    threshold: 0.001
    on_violation:
      action: "auto_remediate"
      create_ticket: true
      auto_approve: true

  - id: "inv-003"
    name: "capacity_headroom"
    description: "Must maintain 20% capacity headroom"
    promql: "ratelimiter_capacity_available_ratio"
    operator: "gt"
    threshold: 0.2
    on_violation:
      action: "auto_remediate"
      create_ticket: true
      auto_approve: true
```

**API:**

```
GET    /invariants            # List all invariants
POST   /invariants            # Propose new invariant
PATCH  /invariants/{id}       # Update invariant (status, condition)
GET    /invariants/{id}/status # Current evaluation status (queries Prometheus)
GET    /invariants/{id}/history # Violation history
```

### 3. Action Executor

Bounded execution of system changes.

**Action Types:**

```yaml
action:
  type: enum
  
  # Code change
  code_change:
    repo: string
    branch: string
    files_changed: [{path, diff}]
    commit_message: string
    
  # Deployment
  deployment:
    service: string
    version: string
    strategy: enum            # rolling, canary, blue_green
    
  # Config update
  config_update:
    service: string
    key: string
    old_value: any
    new_value: any
    
  # Query (read-only)
  query:
    target: string            # events, metrics, health
    parameters: object
```

**API:**

```
POST   /actions/execute       # Execute an action
GET    /actions               # List recent actions
GET    /actions/{id}          # Get action details + result
POST   /actions/{id}/rollback # Rollback an action (if supported)
```

### 6. Agent Loop

The core AI execution loop. This is where Claude operates.

**Loop Structure:**

```
while True:
    # 1. Check for work
    ticket = get_next_ticket(status="pending", priority="desc")
    if not ticket:
        # 2. Check invariants for violations
        violations = check_invariants()
        for v in violations:
            if v.on_violation.create_ticket:
                create_ticket(type="investigation", source=v)
        
        # 3. Look for opportunities (anomalies, trends)
        anomalies = detect_anomalies()
        for a in anomalies:
            create_ticket(type="investigation", source=a)
        
        sleep(interval)
        continue
    
    # 4. Plan
    plan = create_plan(ticket)
    update_ticket(ticket, plan=plan)
    
    # 5. Check if approval needed
    if requires_approval(ticket, plan):
        update_ticket(ticket, status="blocked", waiting_for="approval")
        continue
    
    # 6. Execute
    update_ticket(ticket, status="in_progress")
    result = execute_plan(plan)
    
    # 7. Verify
    success = verify_success_criteria(ticket, result)
    
    # 8. Close or escalate
    if success:
        update_ticket(ticket, status="completed", outcome=result)
    else:
        update_ticket(ticket, status="failed", outcome=result)
        maybe_create_followup_ticket(ticket, result)
```

---

## Claude Integration (The Brain)

The agent loop uses Claude as the reasoning engine. Claude receives context and tools, then decides what to do.

### Tool-Based Architecture

Claude doesn't execute code directly. It calls tools that the harness provides. Each tool is a bounded, auditable action.

**Available Tools:**

```python
TOOLS = [
    # Observability (read-only)
    {
        "name": "query_prometheus",
        "description": "Execute a PromQL query against Prometheus",
        "parameters": {
            "query": "string - PromQL query",
            "start": "string - ISO timestamp (optional)",
            "end": "string - ISO timestamp (optional)",
            "step": "string - query resolution (optional)"
        }
    },
    {
        "name": "query_loki",
        "description": "Query structured logs from Loki",
        "parameters": {
            "query": "string - LogQL query",
            "start": "string - ISO timestamp",
            "end": "string - ISO timestamp",
            "limit": "int - max results (optional)"
        }
    },
    
    # Knowledge (read-only)
    {
        "name": "read_file",
        "description": "Read a file from the repository",
        "parameters": {
            "path": "string - path relative to repo root"
        }
    },
    {
        "name": "list_directory",
        "description": "List files in a directory",
        "parameters": {
            "path": "string - path relative to repo root"
        }
    },
    {
        "name": "search_code",
        "description": "Search for patterns in the codebase",
        "parameters": {
            "pattern": "string - regex pattern",
            "path": "string - directory to search (optional)"
        }
    },
    
    # Actions (write, require approval for some)
    {
        "name": "edit_file",
        "description": "Edit a file in the repository. Creates a git commit.",
        "parameters": {
            "path": "string - path relative to repo root",
            "original": "string - exact text to replace",
            "replacement": "string - new text"
        }
    },
    {
        "name": "create_file",
        "description": "Create a new file. Creates a git commit.",
        "parameters": {
            "path": "string - path relative to repo root",
            "content": "string - file content"
        }
    },
    {
        "name": "run_tests",
        "description": "Run the test suite for a service",
        "parameters": {
            "service": "string - service name",
            "filter": "string - test filter pattern (optional)"
        }
    },
    {
        "name": "deploy",
        "description": "Deploy a service. Requires approval if production.",
        "parameters": {
            "service": "string - service name",
            "version": "string - git ref to deploy (optional, defaults to HEAD)"
        }
    },
    {
        "name": "update_config",
        "description": "Update a runtime configuration value",
        "parameters": {
            "service": "string - service name",
            "key": "string - config key",
            "value": "string - new value"
        }
    },
    
    # Ticket management
    {
        "name": "create_ticket",
        "description": "Create a new ticket for follow-up work",
        "parameters": {
            "type": "string - feature|improvement|incident|investigation",
            "description": "string - what needs to be done",
            "context": "object - relevant context"
        }
    },
    {
        "name": "add_ticket_note",
        "description": "Add a note to the current ticket",
        "parameters": {
            "note": "string - note content"
        }
    }
]
```

### The Agentic Loop

```python
# src/agent_loop/loop.py
import anthropic
from .tools import TOOLS, execute_tool
from .display import log, log_plan, log_tool_call, log_tool_result

client = anthropic.Client()

def run_agent_on_ticket(ticket: Ticket) -> TicketOutcome:
    """Run Claude in a loop until the ticket is resolved."""
    
    # Build initial context
    messages = [{
        "role": "user",
        "content": build_ticket_prompt(ticket)
    }]
    
    # System prompt with role and constraints
    system = build_system_prompt(ticket)
    
    while True:
        # Call Claude
        response = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=4096,
            system=system,
            tools=TOOLS,
            messages=messages
        )
        
        # Check if Claude is done
        if response.stop_reason == "end_turn":
            # Claude finished without tool calls - extract outcome
            return extract_outcome(response, ticket)
        
        # Process tool calls
        if response.stop_reason == "tool_use":
            tool_results = []
            
            for block in response.content:
                if block.type == "tool_use":
                    log_tool_call(block.name, block.input)
                    
                    # Execute the tool
                    result = execute_tool(
                        name=block.name,
                        params=block.input,
                        ticket=ticket
                    )
                    
                    log_tool_result(block.name, result)
                    
                    tool_results.append({
                        "type": "tool_result",
                        "tool_use_id": block.id,
                        "content": result.to_string()
                    })
            
            # Add assistant response and tool results to conversation
            messages.append({"role": "assistant", "content": response.content})
            messages.append({"role": "user", "content": tool_results})
        
        # Safety: limit iterations
        if len(messages) > 50:
            return TicketOutcome(
                status="failed",
                reason="Exceeded maximum iterations"
            )


def build_system_prompt(ticket: Ticket) -> str:
    return f"""You are an AI agent operating infrastructure for the harness system.

## Your Role
You are working on ticket {ticket.id}: {ticket.objective.description}

## Success Criteria
{format_success_criteria(ticket.objective.success_criteria)}

## Constraints
{format_constraints(ticket.constraints)}

## Available Tools
You have tools to:
- Query metrics (Prometheus) and logs (Loki)
- Read and search the codebase
- Edit files (creates git commits)
- Run tests
- Deploy services
- Update configuration

## Process
1. First, understand the current state by querying metrics/logs
2. Investigate the codebase if you need to make changes
3. Make changes incrementally, testing as you go
4. Verify your changes meet the success criteria
5. When done, summarize what you did and the outcome

## Rules
- Always run tests before deploying
- Make small, incremental changes
- If something fails, investigate before retrying
- If you're stuck, add a note to the ticket and stop
- Never make changes outside the subjects/ directory

Begin by investigating the current state.
"""


def build_ticket_prompt(ticket: Ticket) -> str:
    return f"""# Ticket {ticket.id}

## Objective
{ticket.objective.description}

## Success Criteria
{format_success_criteria(ticket.objective.success_criteria)}

## Context
{format_context(ticket.context)}

## Related Documentation
{format_related_docs(ticket.context.related_docs)}

Please begin working on this ticket. Start by understanding the current state.
"""
```

### Tool Execution

Tools are executed in a sandboxed environment. All actions are logged and auditable.

```python
# src/agent_loop/tools.py
from dataclasses import dataclass
from typing import Any
import subprocess
import git

@dataclass
class ToolResult:
    success: bool
    data: Any
    error: str | None = None
    
    def to_string(self) -> str:
        if self.success:
            return json.dumps(self.data, indent=2)
        return f"Error: {self.error}"


def execute_tool(name: str, params: dict, ticket: Ticket) -> ToolResult:
    """Execute a tool and return the result."""
    
    # Log to action history
    action_id = log_action_start(ticket.id, name, params)
    
    try:
        result = TOOL_HANDLERS[name](params, ticket)
        log_action_complete(action_id, result)
        return result
    except Exception as e:
        error_result = ToolResult(success=False, data=None, error=str(e))
        log_action_failed(action_id, e)
        return error_result


TOOL_HANDLERS = {
    "query_prometheus": handle_query_prometheus,
    "query_loki": handle_query_loki,
    "read_file": handle_read_file,
    "list_directory": handle_list_directory,
    "search_code": handle_search_code,
    "edit_file": handle_edit_file,
    "create_file": handle_create_file,
    "run_tests": handle_run_tests,
    "deploy": handle_deploy,
    "update_config": handle_update_config,
    "create_ticket": handle_create_ticket,
    "add_ticket_note": handle_add_ticket_note,
}


def handle_edit_file(params: dict, ticket: Ticket) -> ToolResult:
    """Edit a file and create a git commit."""
    path = params["path"]
    original = params["original"]
    replacement = params["replacement"]
    
    # Security: ensure path is within allowed directories
    if not is_path_allowed(path):
        return ToolResult(
            success=False,
            data=None,
            error=f"Path not allowed: {path}"
        )
    
    # Read current content
    full_path = REPO_ROOT / path
    if not full_path.exists():
        return ToolResult(
            success=False,
            data=None,
            error=f"File not found: {path}"
        )
    
    content = full_path.read_text()
    
    # Verify original text exists exactly once
    count = content.count(original)
    if count == 0:
        return ToolResult(
            success=False,
            data=None,
            error=f"Original text not found in {path}"
        )
    if count > 1:
        return ToolResult(
            success=False,
            data=None,
            error=f"Original text found {count} times in {path}, must be unique"
        )
    
    # Make the replacement
    new_content = content.replace(original, replacement, 1)
    full_path.write_text(new_content)
    
    # Create git commit
    repo = git.Repo(REPO_ROOT)
    repo.index.add([path])
    commit = repo.index.commit(
        f"[{ticket.id}] Edit {path}\n\nAutomated change by harness agent."
    )
    
    return ToolResult(
        success=True,
        data={
            "path": path,
            "commit": commit.hexsha[:8],
            "lines_changed": len(replacement.split('\n'))
        }
    )


def handle_deploy(params: dict, ticket: Ticket) -> ToolResult:
    """Deploy a service."""
    service = params["service"]
    version = params.get("version", "HEAD")
    
    # Check if approval required
    if requires_deployment_approval(service):
        return ToolResult(
            success=False,
            data=None,
            error="Deployment requires approval. Ticket has been flagged."
        )
    
    # Run deployment script
    result = subprocess.run(
        ["./scripts/deploy.sh", service, version],
        capture_output=True,
        text=True,
        timeout=300
    )
    
    if result.returncode != 0:
        return ToolResult(
            success=False,
            data=None,
            error=f"Deployment failed: {result.stderr}"
        )
    
    # Parse deployment output for version info
    deployed_version = parse_deployed_version(result.stdout)
    
    return ToolResult(
        success=True,
        data={
            "service": service,
            "version": deployed_version,
            "output": result.stdout
        }
    )


def handle_run_tests(params: dict, ticket: Ticket) -> ToolResult:
    """Run tests for a service."""
    service = params["service"]
    filter_pattern = params.get("filter", "")
    
    cmd = ["python", "-m", "pytest", f"subjects/{service}/tests/"]
    if filter_pattern:
        cmd.extend(["-k", filter_pattern])
    cmd.extend(["--tb=short", "-q"])
    
    result = subprocess.run(
        cmd,
        capture_output=True,
        text=True,
        timeout=120,
        cwd=REPO_ROOT
    )
    
    # Parse test output
    passed, failed, total = parse_pytest_output(result.stdout)
    
    return ToolResult(
        success=(result.returncode == 0),
        data={
            "passed": passed,
            "failed": failed,
            "total": total,
            "output": result.stdout if result.returncode != 0 else None
        },
        error=result.stderr if result.returncode != 0 else None
    )
```

### Approval Flow

Some actions require human approval. The agent loop handles this gracefully.

```python
def requires_approval(ticket: Ticket, action: str, params: dict) -> bool:
    """Check if an action requires human approval."""
    
    # High-risk actions always need approval
    if action == "deploy" and is_production(params.get("service")):
        return True
    
    # Large changes need approval
    if action == "edit_file":
        lines_changed = len(params.get("replacement", "").split('\n'))
        if lines_changed > 50:
            return True
    
    # Ticket-level approval settings
    if ticket.approval.required and not ticket.approval.approved_at:
        return True
    
    return False


# In the tool executor:
def execute_tool(name: str, params: dict, ticket: Ticket) -> ToolResult:
    if requires_approval(ticket, name, params):
        # Flag ticket for approval
        update_ticket(
            ticket.id,
            status="blocked",
            waiting_for="approval",
            pending_action={"tool": name, "params": params}
        )
        return ToolResult(
            success=False,
            data=None,
            error="Action requires approval. Ticket flagged for review."
        )
    
    # ... execute normally
```

### 7. Dashboard (Demo Interface)

A single-page view showing the loop in action.

**Sections:**

1. **Current State**
   - Service name, status (healthy/degraded/unhealthy)
   - Uptime, deployment count
   - Human interventions counter (goal: 0)
   - AI actions counter

2. **Invariants**
   - List of all invariants with current status
   - ✓ passing, ⚠ warning, ✗ violated
   - Current value vs threshold

3. **Recent Activity**
   - Timeline of agent actions
   - "10:42 AI detected traffic spike..."
   - "10:43 AI created ticket..."
   - Links to ticket details

4. **Ticket Queue**
   - Active tickets with status
   - Click through to details

5. **Code Changes**
   - Recent commits by AI
   - Diff links

---

## The Rate Limiter (First Subject)

A token bucket rate limiter built and operated entirely through the harness.

### Service API

```
POST /check
  Request:  { client_id, tokens_requested }
  Response: { allowed, remaining, reset_at }

POST /configure
  Request:  { client_id, bucket_size, refill_rate }
  Response: { success }

GET /status
  Response: { healthy, components: [...] }

GET /client/{id}
  Response: { bucket_size, refill_rate, current_tokens, config_history }
```

### Observability

**Prometheus Metrics:**

```python
from prometheus_client import Counter, Histogram, Gauge

# Request metrics
ratelimiter_requests_total = Counter(
    'ratelimiter_requests_total',
    'Total requests processed',
    ['client_id', 'allowed']  # allowed: "true" or "false"
)

ratelimiter_latency_seconds = Histogram(
    'ratelimiter_latency_seconds',
    'Request latency in seconds',
    ['endpoint'],
    buckets=[.001, .005, .01, .025, .05, .1, .25, .5, 1.0]
)

# Capacity metrics
ratelimiter_bucket_tokens = Gauge(
    'ratelimiter_bucket_tokens',
    'Current tokens in bucket',
    ['client_id']
)

ratelimiter_capacity_available_ratio = Gauge(
    'ratelimiter_capacity_available_ratio',
    'Ratio of available capacity (0-1)'
)
```

**Loki Structured Logs:**

```python
# On every request
logger.info("request.processed", extra={
    "client_id": client_id,
    "tokens_requested": tokens,
    "allowed": allowed,
    "remaining": remaining,
    "latency_ms": latency_ms
})

# On configuration change
logger.info("client.configured", extra={
    "client_id": client_id,
    "bucket_size": bucket_size,
    "refill_rate": refill_rate,
    "configured_by": "agent",
    "ticket_id": ticket_id
})
```

### Initial Invariants

```yaml
invariants:
  - name: latency_slo
    promql: "histogram_quantile(0.99, rate(ratelimiter_latency_seconds_bucket[5m]))"
    operator: lt
    threshold: 0.01  # 10ms
    on_violation: investigate

  - name: error_rate
    promql: |
      sum(rate(ratelimiter_requests_total{allowed="false"}[5m])) 
      / sum(rate(ratelimiter_requests_total[5m]))
    operator: lt
    threshold: 0.001  # 0.1%
    on_violation: auto_remediate

  - name: capacity_headroom
    promql: "ratelimiter_capacity_available_ratio"
    operator: gt
    threshold: 0.2  # 20%
    on_violation: auto_remediate
```

### Runbook: High Error Rate

```yaml
runbook: high_error_rate
trigger: invariant_violation(error_rate)

steps:
  - name: diagnose
    action: query_loki
    params:
      query: '{service="ratelimiter"} |= "request.processed" | json | allowed="false"'
      window: "15m"
    output: rejected_requests
    
  - name: analyze_by_client
    action: query_prometheus
    params:
      query: 'topk(5, sum by (client_id) (rate(ratelimiter_requests_total{allowed="false"}[15m])))'
    output: top_rejected_clients
    
  - name: check_capacity
    action: query_prometheus
    params:
      query: 'ratelimiter_capacity_available_ratio'
    branch:
      - condition: "result < 0.2"
        next: scale_up
      - default: investigate_clients
    
  - name: scale_up
    action: config_update
    params:
      service: "ratelimiter"
      key: "max_concurrent"
      value: "current * 1.5"
    next: verify
    
  - name: investigate_clients
    action: create_ticket
    params:
      type: "investigation"
      description: "High rejection rate not caused by capacity"
      context: 
        top_clients: "{{top_rejected_clients}}"
    next: close
    
  - name: verify
    action: wait_and_check
    params:
      wait: "5m"
      promql: |
        sum(rate(ratelimiter_requests_total{allowed="false"}[5m])) 
        / sum(rate(ratelimiter_requests_total[5m])) < 0.001
    branch:
      - condition: "success"
        next: close
      - default: escalate
        
  - name: escalate
    action: update_ticket
    params:
      status: "blocked"
      note: "Auto-remediation failed, requires human review"
```

---

## Repository Structure

```
harness/
├── AGENTS.md                    # Entry point for AI
├── README.md
├── .env.example                 # Grafana Cloud credentials template
│
├── api/
│   ├── schema/
│   │   ├── tickets.yaml         # Ticket schema
│   │   ├── invariants.yaml      # Invariant schema
│   │   └── actions.yaml         # Action schema
│   └── openapi.yaml             # Full API spec
│
├── src/
│   ├── ticket_system/
│   │   ├── README.md
│   │   ├── models.py
│   │   ├── store.py             # SQLite-backed
│   │   └── api.py
│   │
│   ├── observability/
│   │   ├── README.md
│   │   ├── prometheus.py        # Query wrapper for Prometheus API
│   │   ├── loki.py              # Query wrapper for Loki API
│   │   └── emitter.py           # Helper for services to emit metrics/logs
│   │
│   ├── invariant_evaluator/
│   │   ├── README.md
│   │   ├── models.py
│   │   ├── evaluator.py         # Runs PromQL queries, checks thresholds
│   │   └── api.py
│   │
│   ├── action_executor/
│   │   ├── README.md
│   │   ├── models.py
│   │   ├── executor.py
│   │   └── api.py
│   │
│   ├── agent_loop/
│   │   ├── README.md
│   │   ├── loop.py
│   │   ├── planner.py
│   │   └── tools.py             # Tools the agent can call
│   │
│   └── dashboard/
│       ├── README.md
│       ├── app.py               # FastAPI + Jinja2
│       └── templates/
│           └── index.html       # htmx-powered UI
│
├── runbooks/
│   ├── README.md
│   └── high_error_rate.yaml
│
├── subjects/
│   └── ratelimiter/
│       ├── AGENTS.md
│       ├── README.md
│       ├── api/
│       │   └── schema.yaml
│       ├── src/
│       │   ├── service.py
│       │   ├── bucket.py
│       │   └── api.py
│       ├── config/
│       │   ├── schema.yaml
│       │   └── defaults.yaml
│       └── invariants/
│           └── initial.yaml
│
├── docs/
│   ├── architecture.md
│   └── decisions/
│       └── 001_event_schema.md
│
└── tests/
    ├── harness/
    └── subjects/
        └── ratelimiter/
```

---

## AGENTS.md (Harness Root)

```markdown
# AI-Native Infrastructure Harness

## What is this?

A framework for AI-driven development and operation of infrastructure services.

## Quick Reference

| I need to...                        | Look here                           |
|-------------------------------------|-------------------------------------|
| Understand the architecture         | docs/architecture.md                |
| See API schemas                     | api/schema/                         |
| Find a component                    | src/{component}/README.md           |
| See runbooks                        | runbooks/                           |
| Work on the rate limiter            | subjects/ratelimiter/AGENTS.md      |

## Conventions

- All APIs defined in api/schema/ as YAML
- All components have interface.py defining public contract
- All events follow schema in api/schema/events.yaml
- All tickets follow schema in api/schema/tickets.yaml

## The Loop

1. Check ticket queue for pending work
2. If no tickets, check invariants for violations
3. If violation, create investigation ticket
4. Pick ticket, create plan, execute, verify, close

## Current State

[This section updated by the harness itself]

- Active tickets: [count]
- Invariant status: [all passing / N violations]
- Last deployment: [timestamp]
- Human interventions (30d): [count]
```

---

## Implementation Order

### Phase 1: Foundation (Week 1)

1. **Grafana Cloud Setup** — Create free account, get API keys
2. **Observability Wrappers** — Python helpers to query Prometheus/Loki
3. **Ticket System** — SQLite-backed, full CRUD API
4. **Dashboard** — Basic web UI showing state

### Phase 2: Execution Layer (Week 2)

5. **Action Executor** — Code changes (local git), config updates
6. **Invariant Evaluator** — Queries Prometheus, checks thresholds, creates tickets
7. **Agent Loop** — Basic loop that processes tickets

### Phase 3: Rate Limiter (Week 3)

8. **Rate Limiter Service** — Token bucket with Prometheus metrics + Loki logs
9. **Integration** — Service emits to Grafana Cloud, harness queries
10. **First Tickets** — Bootstrap via tickets, AI improves

### Phase 4: Polish (Week 4)

11. **Runbooks** — Machine-readable remediation
12. **Dashboard Enhancement** — Activity timeline, ticket details, Grafana embeds
13. **Demo Mode** — Simulated traffic, triggered anomalies

---

## Success Metrics

The demo is successful when:

1. **Zero human interventions** — The rate limiter runs for 7+ days with no SSH, no manual fixes, no direct code changes outside the harness

2. **AI-generated improvements** — At least 3 tickets created by the AI (not seeded by humans) that result in measurable improvements

3. **Visible loop** — Dashboard shows the complete cycle: observation → ticket → plan → action → verification

4. **Audit trail** — Every change traceable to a ticket, every ticket traceable to an observation or request

---

## Tech Stack

- **Language:** Python 3.11+
- **Web Framework:** FastAPI
- **Database:** SQLite (tickets, invariants, action log)
- **Dashboard:** FastAPI + Jinja2 + htmx (no build step)
- **Observability:** Grafana Cloud Free Tier (Prometheus + Loki)
- **AI Integration:** Claude API via Anthropic SDK
- **Git Operations:** GitPython

**Key Dependencies:**

```
fastapi
uvicorn
sqlalchemy
httpx              # For Grafana Cloud API calls
prometheus-client  # For emitting metrics
python-logging-loki  # For structured logs
anthropic          # Claude API
gitpython          # Git operations
jinja2             # Templates
rich               # Pretty terminal output
```

Keep it simple. The harness should be understandable by reading the code.

---

## Watching It Work

The agent loop should be satisfying to watch. Use `rich` for pretty terminal output that makes the loop visible.

**Example Output:**

```
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃  🔄 HARNESS AGENT                                            cycle #847     ┃
┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛

  ┌─ INVARIANTS ──────────────────────────────────────────────────────────────┐
  │  ✓ latency_slo          p99 = 4.2ms       (< 10ms)                        │
  │  ✓ error_rate           0.02%             (< 0.1%)                        │
  │  ⚠ capacity_headroom    22%               (> 20%)  ← watching             │
  └───────────────────────────────────────────────────────────────────────────┘

  ┌─ TICKET QUEUE ────────────────────────────────────────────────────────────┐
  │  #127  ● in_progress   optimize bucket refill timing                      │
  │  #128  ○ pending       investigate client-47 traffic pattern              │
  └───────────────────────────────────────────────────────────────────────────┘

14:23:01 │ ░░ Checking invariants...
14:23:01 │ ✓  All invariants passing
14:23:01 │ ░░ Checking ticket queue...
14:23:01 │ 🎫 Picking up TKT-127: optimize bucket refill timing

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
  WORKING ON TKT-127
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

14:23:02 │ 🧠 Planning approach...
         │
         │ ┌─ PLAN ───────────────────────────────────────────────────────────┐
         │ │ 1. Query current refill timing metrics                          │
         │ │ 2. Analyze token exhaustion patterns by client                  │
         │ │ 3. Test alternative refill strategies in simulation             │
         │ │ 4. Implement best strategy                                      │
         │ │ 5. Deploy and verify latency impact                             │
         │ └──────────────────────────────────────────────────────────────────┘
         │
14:23:05 │ 🔍 Querying Prometheus: rate(ratelimiter_bucket_exhaustions[1h])
14:23:05 │    → 847 exhaustion events, 73% from 5 clients
         │
14:23:08 │ 🔍 Querying Loki: {service="ratelimiter"} |= "bucket.exhausted"
14:23:08 │    → Pattern: bursts at minute boundaries
         │
14:23:12 │ 💡 Insight: Clients request tokens in synchronized bursts
         │    Current: refill 100 tokens/second
         │    Proposed: refill 25 tokens/250ms (smoother)
         │
14:23:15 │ 📝 Modifying: subjects/ratelimiter/src/bucket.py
         │
         │    - self.refill_interval = 1.0
         │    - self.refill_amount = self.rate
         │    + self.refill_interval = 0.25
         │    + self.refill_amount = self.rate / 4
         │
14:23:18 │ 🧪 Running tests...
14:23:24 │ ✓  All tests passing (47/47)
         │
14:23:25 │ 🚀 Deploying...
14:23:28 │ ✓  Deployment complete: v1.4.7
         │
14:23:28 │ ⏳ Waiting 5m to verify...

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

14:28:30 │ 📊 Verifying success criteria...
         │    bucket_exhaustions: 847 → 312  ✓ (63% reduction)
         │    p99_latency: 4.2ms → 3.8ms     ✓ (no regression)
         │
14:28:30 │ ✅ TKT-127 COMPLETED
         │
         │ ┌─ OUTCOME ────────────────────────────────────────────────────────┐
         │ │ Reduced bucket exhaustion events by 63% by switching from       │
         │ │ 1-second refill intervals to 250ms intervals. No latency        │
         │ │ regression observed. Change deployed in v1.4.7.                 │
         │ └──────────────────────────────────────────────────────────────────┘

14:28:31 │ ░░ Sleeping 30s before next cycle...
```

**Implementation:**

```python
# src/agent_loop/display.py
from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich.live import Live
from rich import box

console = Console()

def print_header(cycle: int):
    console.print(Panel(
        f"[bold]🔄 HARNESS AGENT[/bold]                                            cycle #{cycle}",
        box=box.HEAVY,
        style="blue"
    ))

def print_invariants(invariants: list[dict]):
    table = Table(box=box.ROUNDED, show_header=False, padding=(0, 2))
    table.add_column("status", width=3)
    table.add_column("name", width=20)
    table.add_column("current", width=20)
    table.add_column("threshold", width=15)
    
    for inv in invariants:
        status = "✓" if inv["passing"] else "⚠" if inv["warning"] else "✗"
        style = "green" if inv["passing"] else "yellow" if inv["warning"] else "red"
        table.add_row(
            f"[{style}]{status}[/]",
            inv["name"],
            f"{inv['current_value']}",
            f"({inv['operator']} {inv['threshold']})"
        )
    
    console.print(Panel(table, title="INVARIANTS", box=box.ROUNDED))

def log(message: str, emoji: str = "░░", indent: int = 0):
    timestamp = datetime.now().strftime("%H:%M:%S")
    prefix = " " * indent
    console.print(f"[dim]{timestamp}[/] │ {prefix}{emoji} {message}")

def log_plan(steps: list[str]):
    table = Table(box=box.ROUNDED, show_header=False, padding=(0, 1))
    for i, step in enumerate(steps, 1):
        table.add_row(f"{i}.", step)
    console.print(Panel(table, title="PLAN", box=box.ROUNDED))

def log_diff(filename: str, old_lines: list[str], new_lines: list[str]):
    console.print(f"         │ 📝 Modifying: [cyan]{filename}[/]")
    console.print("         │")
    for line in old_lines:
        console.print(f"         │    [red]- {line}[/]")
    for line in new_lines:
        console.print(f"         │    [green]+ {line}[/]")

def log_success(ticket_id: str, outcome: str):
    console.print(f"         │ ✅ [bold green]{ticket_id} COMPLETED[/]")
    console.print("         │")
    console.print(Panel(outcome, title="OUTCOME", box=box.ROUNDED))
```

**Compact Mode:**

For long-running background operation, support a compact mode:

```
14:23:01 ✓ invariants ok │ 14:23:02 🎫 TKT-127 │ 14:23:15 📝 bucket.py │ 14:23:28 🚀 v1.4.7 │ 14:28:30 ✅ done
14:28:31 ✓ invariants ok │ 14:28:32 🎫 TKT-128 │ ...
```

**Watch Mode:**

```bash
# Full output (default)
python -m harness.agent

# Compact single-line mode
python -m harness.agent --compact

# Follow specific ticket
python -m harness.agent --follow TKT-127

# Dashboard mode (curses-based live view)
python -m harness.agent --dashboard
```

---

## Getting Started

```bash
# Clone and setup
git clone <repo>
cd harness
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Configure Grafana Cloud (get these from grafana.com)
cp .env.example .env
# Edit .env with your GRAFANA_CLOUD_API_KEY, PROMETHEUS_URL, LOKI_URL

# Initialize database
python -m harness.init

# Start the harness (tickets API, invariant evaluator, dashboard)
python -m harness.serve

# Start the agent loop (in another terminal)
python -m harness.agent

# Start the rate limiter subject (in another terminal)
python -m subjects.ratelimiter.serve

# Open dashboard
open http://localhost:8000
```